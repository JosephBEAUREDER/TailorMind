{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from django.conf import settings\n",
    "from django.contrib.auth.models import User\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path for the Chroma database\n",
    "persist_directory = 'db'\n",
    "\n",
    "def create_and_persist_db(user, document_path):\n",
    "    \"\"\"Create and persist a vector store for a specific user.\"\"\"\n",
    "    persist_directory = get_user_db_path(user)\n",
    "    os.makedirs(persist_directory, exist_ok=True)\n",
    "\n",
    "    # Load and process the documents\n",
    "    loader = TextLoader(document_path, encoding='utf-8')\n",
    "    documents = loader.load()\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "\n",
    "    # Create the vector store\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vectorstore = Chroma.from_documents(texts, embeddings, persist_directory=persist_directory)\n",
    "    vectorstore.persist()\n",
    "    print(f\"Database created and persisted for user {user.username}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 4579, which is longer than the specified 1000\n",
      "Created a chunk of size 10601, which is longer than the specified 1000\n",
      "Created a chunk of size 4132, which is longer than the specified 1000\n",
      "Created a chunk of size 1440, which is longer than the specified 1000\n",
      "Created a chunk of size 4505, which is longer than the specified 1000\n",
      "Created a chunk of size 6090, which is longer than the specified 1000\n",
      "Created a chunk of size 3659, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database created and persisted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\josep\\projects\\TailorMind\\env\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "create_and_persist_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1) \"La pensée philosophique contribue à engendrer les formes les plus caractéristiques et les plus tenaces de la mythologie et de l’erreur, qu’elle devrait avoir en même temps pour fonction de dénoncer et de combattre.\"\n",
      "2) \"Les philosophes qui appellent aujourd’hui à l’insurrection contre tout espèce d’ordre, de logique ou de méthode font songer irrésistiblement à certains programmes politiques dans lesquels il est question de réaliser le bonheur de tout le monde en supprimant purement et simplement le gouvernement, les lois, les impôts, la police, les tribunaux et tous les règlements en usage.\"\n",
      "3) \"Les conventions et les règles qui gouvernent le monde de l’esprit deviennent automatiquement répressives, inacceptables et paralysantes, lorsqu’on a décidé d’oublier entièrement la raison d’être qui a pu les inciter et la fonction qu’elles peuvent remplir.\"\n"
     ]
    }
   ],
   "source": [
    "# Function to load the existing database and query it\n",
    "def query_db(user, query):\n",
    "    \"\"\"Query the vector store for a specific user.\"\"\"\n",
    "    persist_directory = get_user_db_path(user)\n",
    "\n",
    "    # Check if the user's database exists\n",
    "    if not os.path.exists(persist_directory):\n",
    "        raise ValueError(f\"No database found for user {user.username}\")\n",
    "\n",
    "    # Load the persisted database\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vectorstore = Chroma(persist_directory=persist_directory, embedding_function=embeddings)\n",
    "\n",
    "    # Create the RAG chain\n",
    "    qa = RetrievalQA.from_chain_type(\n",
    "        llm=OpenAI(),\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=vectorstore.as_retriever()\n",
    "    )\n",
    "\n",
    "    # Use the RAG system\n",
    "    result = qa.invoke(query)\n",
    "    return result[\"result\"]\n",
    "# Example usage\n",
    "query = \"Donne moi 3 citations aléatoire de Bouveresse\"\n",
    "result = query_db(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
